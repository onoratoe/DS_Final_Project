{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f44245c",
   "metadata": {},
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfa1dd1",
   "metadata": {},
   "source": [
    "Three experiments:\n",
    "- using Logisitc Regression\n",
    "- using Random Decision Trees\n",
    "- using a Bagging Classifier with a Random Decision Tree being the estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90950af",
   "metadata": {},
   "source": [
    "**Import Statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2961be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ff2af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>protocol</th>\n",
       "      <th>www_present</th>\n",
       "      <th>sub_domain</th>\n",
       "      <th>domain</th>\n",
       "      <th>top_domain</th>\n",
       "      <th>dir</th>\n",
       "      <th>file</th>\n",
       "      <th>path</th>\n",
       "      <th>fragment</th>\n",
       "      <th>...</th>\n",
       "      <th>n_hyphens</th>\n",
       "      <th>n_underscore</th>\n",
       "      <th>n_slash</th>\n",
       "      <th>n_questionmrk</th>\n",
       "      <th>n_equals</th>\n",
       "      <th>n_at</th>\n",
       "      <th>n_and</th>\n",
       "      <th>n_exclamation</th>\n",
       "      <th>url_length</th>\n",
       "      <th>domain_name_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://ghfdc.knuodwq.cn/</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://rakutenluyaw.ouxawer-p.net/</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pulsagratiss-1010.000webhostapp.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>idjvn.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.vmveg.com//vendor/phpunit/phpunit/s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98567</th>\n",
       "      <td>interceder.net/topic/Guy-Turcotte</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98568</th>\n",
       "      <td>ifes.org/Divisions/List-Projects.aspx</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98569</th>\n",
       "      <td>en.wikipedia.org/wiki/Jeffrey_Lynn</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98570</th>\n",
       "      <td>ccdowney.com/bible-college/</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98571</th>\n",
       "      <td>sharetv.org/shows/the_late_late_show_with_crai...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98572 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  protocol  \\\n",
       "0                              https://ghfdc.knuodwq.cn/         1   \n",
       "1                    https://rakutenluyaw.ouxawer-p.net/         1   \n",
       "2                    pulsagratiss-1010.000webhostapp.com         0   \n",
       "3                                              idjvn.com         0   \n",
       "4      http://www.vmveg.com//vendor/phpunit/phpunit/s...         1   \n",
       "...                                                  ...       ...   \n",
       "98567                  interceder.net/topic/Guy-Turcotte         0   \n",
       "98568              ifes.org/Divisions/List-Projects.aspx         0   \n",
       "98569                 en.wikipedia.org/wiki/Jeffrey_Lynn         0   \n",
       "98570                        ccdowney.com/bible-college/         0   \n",
       "98571  sharetv.org/shows/the_late_late_show_with_crai...         0   \n",
       "\n",
       "       www_present  sub_domain  domain  top_domain  dir  file  path  fragment  \\\n",
       "0                0           1       1           1    0     0     1         0   \n",
       "1                0           1       1           1    0     0     1         0   \n",
       "2                0           1       1           1    0     0     0         0   \n",
       "3                0           0       1           1    0     0     0         0   \n",
       "4                1           1       1           1    0     1     1         0   \n",
       "...            ...         ...     ...         ...  ...   ...   ...       ...   \n",
       "98567            0           0       1           1    1     1     1         0   \n",
       "98568            0           0       1           1    1     1     1         0   \n",
       "98569            0           1       1           1    1     1     1         0   \n",
       "98570            0           0       1           1    1     0     1         0   \n",
       "98571            0           0       1           1    1     1     1         0   \n",
       "\n",
       "       ...  n_hyphens  n_underscore  n_slash  n_questionmrk  n_equals  n_at  \\\n",
       "0      ...          0             0        3              0         0     0   \n",
       "1      ...          1             0        3              0         0     0   \n",
       "2      ...          1             0        0              0         0     0   \n",
       "3      ...          0             0        0              0         0     0   \n",
       "4      ...          0             0       10              1         0     0   \n",
       "...    ...        ...           ...      ...            ...       ...   ...   \n",
       "98567  ...          1             0        2              0         0     0   \n",
       "98568  ...          1             0        2              0         0     0   \n",
       "98569  ...          0             1        2              0         0     0   \n",
       "98570  ...          1             0        2              0         0     0   \n",
       "98571  ...          0             6        3              0         0     0   \n",
       "\n",
       "       n_and  n_exclamation  url_length  domain_name_correct  \n",
       "0          0              0          25                    1  \n",
       "1          0              0          35                    1  \n",
       "2          0              0          35                    1  \n",
       "3          0              0           9                    0  \n",
       "4          0              0          74                    0  \n",
       "...      ...            ...         ...                  ...  \n",
       "98567      0              0          33                    1  \n",
       "98568      0              0          37                    0  \n",
       "98569      0              0          34                    1  \n",
       "98570      0              0          27                    1  \n",
       "98571      0              0          65                    0  \n",
       "\n",
       "[98572 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"clean_data.csv\")\n",
    "df = df.drop([\"Unnamed: 0.1\", \"Unnamed: 0\"], axis=\"columns\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a8efef",
   "metadata": {},
   "source": [
    "**Determimg the number of outliers and removing them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b536edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  347   447   448   571   601   610   675   686   703   724  1012  1066\n",
      "  1176  1239  1245  1468  1529  1643  1734  1940  1981  2006  2063  2095\n",
      "  2128  2208  2210  2379  2595  2636  2678  2785  3040  3047  3081  3280\n",
      "  3445  3470  3531  3589  3779  3817  3863  3917  4039  4482  4733  4773\n",
      "  4784  5012  5092  5097  5164  5318  5360  5416  5751  5950  6006  6009\n",
      "  6070  6188  6340  6345  6469  6499  6545  6907  6924  6956  6994  7379\n",
      "  7541  7603  7723  7885  7996  8044  8046  8163  8362  8413  8480  8538\n",
      "  8669  8775  8795  8823  8856  8860  9029  9115  9513  9516  9843 10172\n",
      " 10196 10560 10567 10759 10766 10881 10942 11054 11247 11288 11344 11522\n",
      " 11595 11722 11732 11835 11839 12054 12061 12644 12727 12733 12922 13006\n",
      " 13167 13304 13356 13434 13587 13622 13682 13790 13892 14042 14135 14202\n",
      " 14270 14678 14786 14876 15133 15233 15264 15318 15521 15591 15651 15785\n",
      " 15799 15815 15840 15883 15990 16000 16035 16328 16336 16360 16381 16394\n",
      " 16441 16481 16489 16589 16608 16680 16837 17009 17060 17298 17442 17452\n",
      " 17545 17571 17839 17887 18054 18189 18217 18755 18999 19391 19926 20006\n",
      " 20057 20126 20211 20241 20296 20347 20386 20400 20479 20537 20553 20615\n",
      " 20890 21422 21453 21636 21757 21791 22043 22181 22188 22190 22459 22615\n",
      " 22819 22834 22986 22987 22989 23044 23155 23273 23345 23372 23414 23498\n",
      " 23682 23789 23965 24253 24277 24278 24346 24447 24492 24633 24858 25013\n",
      " 25023 25076 25193 25269 25405 25442 25449 25551 25867 25984 26148 26207\n",
      " 26301 26511 26540 26624 26847 26990 27378 27575 27703 27865 27914 27931\n",
      " 27968 28076 28096 28258 28272 28349 28561 28675 28685 28724 28782 28787\n",
      " 28822 28953 29159 29172 29260 29289 29616 29650 29735 29793 29825 29828\n",
      " 29924 30077 30136 30270 30274 30279 30292 30309 30472 30618 30665 30799\n",
      " 30807 30823 30982 31033 31048 31146 31151 31180 31356 31507 31743 31765\n",
      " 32184 32438 32600 32647 32696 32921 33007 33136 33143 33292 33345 33374\n",
      " 33507 33746 34243 34596 34612 34712 35104 35232 35235 35272 35364 35529\n",
      " 35576 35598 36236 36375 36442 36470 36628 36797 37245 37247 37475 37485\n",
      " 37525 37553 37604 37607 37627 37712 37800 37956 38052 38090 38145 38327\n",
      " 38339 38343 38579 38664 38688 38782 38855 38892 38918 38938 38983 39012\n",
      " 39167 39424 39588 39593 39731 39829 39892 39902 39914 40157 40167 40196\n",
      " 40367 40493 40658 40705 40718 40747 40932 40958 41101 41302 41342 41396\n",
      " 41401 41590 41653 41668 41751 41878 41926 41959 42051 42142 42293 42375\n",
      " 42411 42543 42812 43149 43205 43207 43268 43277 43296 43382 43543 43566\n",
      " 43587 43631 43700 43765 44042 44109 44162 44328 44376 44457 44588 44623\n",
      " 44629 44725 44754 44834 44858 44984 45162 45175 45242 45282 45563 45618\n",
      " 45684 45751 45839 45860 45876 45933 45987 46049 46079 46185 46240 46262\n",
      " 46340 46505 46550 46647 46797 47251 47294 47455 47528 47543 47596 47672\n",
      " 47788 47971 48005 48047 49905 56170 56841 57038 61987 62558 65418 65843\n",
      " 66548 67496 70010 70044 70440 70493 75891 75950 76661 77783 78574 78668\n",
      " 79768 79804 83065 83973 84917 85357 91400 91880 95519 96222 96246 96930\n",
      " 97334]\n",
      "Number of outliers: 493\n",
      "(98572, 23)\n"
     ]
    }
   ],
   "source": [
    "# determimg the number of outliers\n",
    "clf = IsolationForest(contamination=0.005)\n",
    "X = df.iloc[:, 1:].dropna()\n",
    "y_pred = clf.fit_predict(X)\n",
    "outliers = np.where(y_pred==-1)\n",
    "outliers = outliers[0]\n",
    "print(outliers)\n",
    "print('Number of outliers:', len(outliers))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7931130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after dropping outliers: 98079\n"
     ]
    }
   ],
   "source": [
    "outliers_exist = df.index.isin(outliers)\n",
    "df_scaled = df[~outliers_exist]\n",
    "print('Number of rows after dropping outliers:', df_scaled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "871e679e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(df['status'].isnull())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab75cbc",
   "metadata": {},
   "source": [
    "**Experiment 1**\n",
    "- Creating out independent and dependent variables\n",
    "- Using a 5-Fold cross validtion\n",
    "- Testing our 5-Fold cross-validation on Logisitc Regression and Random Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f9ef47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression scores: [0.73118883 0.73205546 0.72838499 0.72807912 0.72322202]\n",
      "Random Forest scores: [0.75810563 0.76554853 0.75917618 0.76269372 0.75870507]\n"
     ]
    }
   ],
   "source": [
    "X = df_scaled[[\"n_hyphens\", \"path\", \"url_length\", \"n_period\", \"domain_name_correct\", \"top_domain\"]]\n",
    "y = df_scaled[[\"status\"]]\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=22)\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "logistic_scores = cross_val_score(logistic_model, X, y, cv=kfold)\n",
    "\n",
    "random_forest_model = RandomForestClassifier()\n",
    "\n",
    "random_forest_scores = cross_val_score(random_forest_model, X, y, cv=kfold)\n",
    "\n",
    "# what scores are these?\n",
    "print(f'Logistic Regression scores: {logistic_scores}')\n",
    "print(f'Random Forest scores: {random_forest_scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddcff5a",
   "metadata": {},
   "source": [
    "**Experiment 2:**\n",
    "- Using a Pipeline function to include a Bagging method using a Random Tree\n",
    "- Using SimpleImputer to replace any missing values with a desciprtive stat if any were missed in preprocessing\n",
    "- Using 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50bbf2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = BaggingClassifier(estimator =RandomForestClassifier(),  n_estimators = 12, oob_score = True, random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3083cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data accuracy: [0.76131781 0.76679601 0.7608431  0.7608431  0.76297367]\n",
      "Test data accuracy: [0.74266296 0.76722274 0.75482775 0.74833926 0.75714506]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "pipeline = Pipeline([('imputer', SimpleImputer()), ('bagging decision tree model', \n",
    "                                                    bag)])\n",
    "accuracy_score_train = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "accuracy_score_test = cross_val_score(pipeline, X_test, y_test, cv=5, scoring='accuracy')\n",
    "print(\"Train data accuracy:\", accuracy_score_train)\n",
    "print(\"Test data accuracy:\", accuracy_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc37d39",
   "metadata": {},
   "source": [
    "**Metrics**\n",
    "- The following metrics are used to evaluate the performance of our models\n",
    "    Accuracy, Sensitivity, Specificity, AUC on all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c952af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "logistic_accuracy_test = []\n",
    "logistic_sensitivity_test = []\n",
    "logistic_specificity_test = []\n",
    "logistic_auc_test = []\n",
    "\n",
    "logistic_accuracy_train = []\n",
    "logistic_sensitivity_train = []\n",
    "logistic_specificity_train = []\n",
    "logistic_auc_train = []\n",
    "\n",
    "random_forest_accuracy_test = []\n",
    "random_forest_sensitivity_test = []\n",
    "random_forest_specificity_test = []\n",
    "random_forest_auc_test = []\n",
    "\n",
    "random_forest_accuracy_train = []\n",
    "random_forest_sensitivity_train = []\n",
    "random_forest_specificity_train = []\n",
    "random_forest_auc_train = []\n",
    "\n",
    "bag_accuracy_test = []\n",
    "bag_sensitivity_test = []\n",
    "bag_specificity_test = []\n",
    "bag_auc_test = []\n",
    "\n",
    "bag_accuracy_train = []\n",
    "bag_sensitivity_train = []\n",
    "bag_specificity_train = []\n",
    "bag_auc_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6dac376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/tmp/ipykernel_3269475/3178697760.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  random_forest_model.fit(X_train, y_train)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics for fold 1:\n",
      "Logistic Regression - Accuracy: 0.7302295349400354, Sensitivity: 0.8736701469642238, Specificity: 0.5778420291759758, AUC: 0.7257560880700998\n",
      "Random Forest - Accuracy: 0.7845991104087277, Sensitivity: 0.8763917066653472, Specificity: 0.687081088185044, AUC: 0.7817363974251955\n",
      "Bagging Classifier - Accuracy: 0.7822158214699922, Sensitivity: 0.8755257558513534, Specificity: 0.6830858194243659, AUC: 0.7793057876378596\n",
      "\n",
      "Test Metrics for fold 1:\n",
      "Logistic Regression - Accuracy: 0.7206362153344209, Sensitivity: 0.8624391213597058, Specificity: 0.571323914181057, AUC: 0.7168815177703814\n",
      "Random Forest - Accuracy: 0.7602977161500816, Sensitivity: 0.8539906569923467, Specificity: 0.6616431187859759, AUC: 0.7578168878891614\n",
      "Bagging Classifier - Accuracy: 0.7639172104404568, Sensitivity: 0.8579664049299275, Specificity: 0.6648874934589221, AUC: 0.7614269491944247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/tmp/ipykernel_3269475/3178697760.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  random_forest_model.fit(X_train, y_train)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics for fold 2:\n",
      "Logistic Regression - Accuracy: 0.7286109376393969, Sensitivity: 0.8747217412812268, Specificity: 0.5732916151762942, AUC: 0.7240066782287605\n",
      "Random Forest - Accuracy: 0.784254999171584, Sensitivity: 0.871852584714321, Specificity: 0.6911366444929403, AUC: 0.7814946146036308\n",
      "Bagging Classifier - Accuracy: 0.7816295578807846, Sensitivity: 0.8690328963640861, Specificity: 0.6887176925301711, AUC: 0.7788752944471287\n",
      "\n",
      "Test Metrics for fold 2:\n",
      "Logistic Regression - Accuracy: 0.7311888254486134, Sensitivity: 0.8762065877201711, Specificity: 0.5788648479147068, AUC: 0.727535717817439\n",
      "Random Forest - Accuracy: 0.7639172104404568, Sensitivity: 0.8536172753507811, Specificity: 0.6696979199331033, AUC: 0.7616575976419424\n",
      "Bagging Classifier - Accuracy: 0.7649367862969005, Sensitivity: 0.8537167877400736, Specificity: 0.6716839134524929, AUC: 0.7627003505962833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/tmp/ipykernel_3269475/3178697760.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  random_forest_model.fit(X_train, y_train)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics for fold 3:\n",
      "Logistic Regression - Accuracy: 0.7274001758790768, Sensitivity: 0.8720190188454966, Specificity: 0.5740507326295888, AUC: 0.7230348757375427\n",
      "Random Forest - Accuracy: 0.7846755795725374, Sensitivity: 0.8703350585671479, Specificity: 0.6938448610892285, AUC: 0.7820899598281882\n",
      "Bagging Classifier - Accuracy: 0.7819354345360233, Sensitivity: 0.8663232708451994, Specificity: 0.692453127461793, AUC: 0.7793881991534963\n",
      "\n",
      "Test Metrics for fold 3:\n",
      "Logistic Regression - Accuracy: 0.7328201468189234, Sensitivity: 0.8718558130322837, Specificity: 0.5853120403446103, AUC: 0.7285839266884468\n",
      "Random Forest - Accuracy: 0.7636623164763459, Sensitivity: 0.8466032877797584, Specificity: 0.6756671569657491, AUC: 0.7611352223727537\n",
      "Bagging Classifier - Accuracy: 0.765089722675367, Sensitivity: 0.8461081402257873, Specificity: 0.6791342719058626, AUC: 0.7626212060658251\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/tmp/ipykernel_3269475/3178697760.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  random_forest_model.fit(X_train, y_train)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics for fold 4:\n",
      "Logistic Regression - Accuracy: 0.7289040694340008, Sensitivity: 0.8732324608107773, Specificity: 0.5758626122577596, AUC: 0.7245475365342685\n",
      "Random Forest - Accuracy: 0.7847393038757121, Sensitivity: 0.874916421089126, Specificity: 0.6891182185809569, AUC: 0.7820173198350414\n",
      "Bagging Classifier - Accuracy: 0.7821011177242777, Sensitivity: 0.8700378891062629, Specificity: 0.6888556273304973, AUC: 0.7794467582183802\n",
      "\n",
      "Test Metrics for fold 4:\n",
      "Logistic Regression - Accuracy: 0.7273144371941273, Sensitivity: 0.8754208754208754, Specificity: 0.5701828115150241, AUC: 0.7228018434679498\n",
      "Random Forest - Accuracy: 0.7603996737357259, Sensitivity: 0.8517528223410576, Specificity: 0.6634797226308048, AUC: 0.7576162724859312\n",
      "Bagging Classifier - Accuracy: 0.7623368678629691, Sensitivity: 0.8500693206575559, Specificity: 0.6692582475309939, AUC: 0.7596637840942748\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/tmp/ipykernel_3269475/3178697760.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  random_forest_model.fit(X_train, y_train)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics for fold 5:\n",
      "Logistic Regression - Accuracy: 0.7275565864600326, Sensitivity: 0.870068972361435, Specificity: 0.5770218564914303, AUC: 0.7235454144264327\n",
      "Random Forest - Accuracy: 0.7843597063621534, Sensitivity: 0.8765444350717014, Specificity: 0.6869856910739557, AUC: 0.7817650630728284\n",
      "Bagging Classifier - Accuracy: 0.7818872349102773, Sensitivity: 0.8713094824591873, Specificity: 0.6874312070863253, AUC: 0.7793703447727564\n",
      "\n",
      "Test Metrics for fold 5:\n",
      "Logistic Regression - Accuracy: 0.7315829722151415, Sensitivity: 0.8783053179986238, Specificity: 0.5735013768269435, AUC: 0.7259033474127836\n",
      "Random Forest - Accuracy: 0.7601325516186592, Sensitivity: 0.8526491693699008, Specificity: 0.6604532937936878, AUC: 0.7565512315817943\n",
      "Bagging Classifier - Accuracy: 0.761916900331379, Sensitivity: 0.8535338641502015, Specificity: 0.6632069476805762, AUC: 0.7583704059153888\n",
      "\n",
      "Average Testing Metrics:\n",
      "Logistic Regression - Accuracy: 0.7285101582294403, Sensitivity: 0.8727040875701672, Specificity: 0.5759170255024996, AUC: 0.7243105565363331\n",
      "Random Forest - Accuracy: 0.7615701479451435, Sensitivity: 0.850565731696828, Specificity: 0.6673808297351389, AUC: 0.7589732807159836\n",
      "Bagging Classifier - Accuracy: 0.7636093148186882, Sensitivity: 0.8511788191121568, Specificity: 0.6709305829867241, AUC: 0.7610547010494404\n",
      "OOB Score: 0.7592526508972267\n"
     ]
    }
   ],
   "source": [
    "fold_no = 1\n",
    "for train, test in kf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "    y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "    \n",
    "    logistic_model.fit(X_train, y_train)\n",
    "    logistic_y_pred_train = logistic_model.predict(X_train) # train\n",
    "    logistic_y_pred = logistic_model.predict(X_test) # testing\n",
    "    \n",
    "    logistic_accuracy_test.append(accuracy_score(y_test, logistic_y_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, logistic_y_pred).ravel()\n",
    "    logistic_sensitivity_test.append(tp / (tp + fn))\n",
    "    logistic_specificity_test.append(tn / (tn + fp))\n",
    "    logistic_auc_test.append(roc_auc_score(y_test, logistic_y_pred))\n",
    "    \n",
    "    logistic_accuracy_train.append(accuracy_score(y_train, logistic_y_pred_train))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, logistic_y_pred_train).ravel()\n",
    "    logistic_sensitivity_train.append(tp / (tp + fn))\n",
    "    logistic_specificity_train.append(tn / (tn + fp))\n",
    "    logistic_auc_train.append(roc_auc_score(y_train, logistic_y_pred_train))\n",
    "    \n",
    "    random_forest_model.fit(X_train, y_train)\n",
    "    random_forest_y_pred_train = random_forest_model.predict(X_train) # train\n",
    "    random_forest_y_pred = random_forest_model.predict(X_test) # testing\n",
    "    \n",
    "    random_forest_accuracy_test.append(accuracy_score(y_test, random_forest_y_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, random_forest_y_pred).ravel()\n",
    "    random_forest_sensitivity_test.append(tp / (tp + fn))\n",
    "    random_forest_specificity_test.append(tn / (tn + fp))\n",
    "    random_forest_auc_test.append(roc_auc_score(y_test, random_forest_y_pred))\n",
    "    \n",
    "    random_forest_accuracy_train.append(accuracy_score(y_train, random_forest_y_pred_train))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, random_forest_y_pred_train).ravel()\n",
    "    random_forest_sensitivity_train.append(tp / (tp + fn))\n",
    "    random_forest_specificity_train.append(tn / (tn + fp))\n",
    "    random_forest_auc_train.append(roc_auc_score(y_train, random_forest_y_pred_train))\n",
    "    \n",
    "    bag.fit(X_train, y_train)\n",
    "    bag_y_pred_train = bag.predict(X_train) # train\n",
    "    bag_y_pred = bag.predict(X_test) # testing\n",
    "    \n",
    "    bag_accuracy_test.append(accuracy_score(y_test, bag_y_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, bag_y_pred).ravel()\n",
    "    bag_sensitivity_test.append(tp / (tp + fn))\n",
    "    bag_specificity_test.append(tn / (tn + fp))\n",
    "    bag_auc_test.append(roc_auc_score(y_test, bag_y_pred))\n",
    "    \n",
    "    bag_accuracy_train.append(accuracy_score(y_train, bag_y_pred_train))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, bag_y_pred_train).ravel()\n",
    "    bag_sensitivity_train.append(tp / (tp + fn))\n",
    "    bag_specificity_train.append(tn / (tn + fp))\n",
    "    bag_auc_train.append(roc_auc_score(y_train, bag_y_pred_train))\n",
    "    \n",
    "    print(f\"Train Metrics for fold {fold_no}:\")\n",
    "    print(f\"Logistic Regression - Accuracy: {logistic_accuracy_train[-1]}, Sensitivity: {logistic_sensitivity_train[-1]}, Specificity: {logistic_specificity_train[-1]}, AUC: {logistic_auc_train[-1]}\")\n",
    "    print(f\"Random Forest - Accuracy: {random_forest_accuracy_train[-1]}, Sensitivity: {random_forest_sensitivity_train[-1]}, Specificity: {random_forest_specificity_train[-1]}, AUC: {random_forest_auc_train[-1]}\")\n",
    "    print(f\"Bagging Classifier - Accuracy: {bag_accuracy_train[-1]}, Sensitivity: {bag_sensitivity_train[-1]}, Specificity: {bag_specificity_train[-1]}, AUC: {bag_auc_train[-1]}\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"Test Metrics for fold {fold_no}:\")\n",
    "    print(f\"Logistic Regression - Accuracy: {logistic_accuracy_test[-1]}, Sensitivity: {logistic_sensitivity_test[-1]}, Specificity: {logistic_specificity_test[-1]}, AUC: {logistic_auc_test[-1]}\")\n",
    "    print(f\"Random Forest - Accuracy: {random_forest_accuracy_test[-1]}, Sensitivity: {random_forest_sensitivity_test[-1]}, Specificity: {random_forest_specificity_test[-1]}, AUC: {random_forest_auc_test[-1]}\")\n",
    "    print(f\"Bagging Classifier - Accuracy: {bag_accuracy_test[-1]}, Sensitivity: {bag_sensitivity_test[-1]}, Specificity: {bag_specificity_test[-1]}, AUC: {bag_auc_test[-1]}\")\n",
    "    print()\n",
    "    \n",
    "    fold_no += 1\n",
    "\n",
    "print(\"Average Testing Metrics:\")\n",
    "print(f\"Logistic Regression - Accuracy: {sum(logistic_accuracy_test) / len(logistic_accuracy_test)}, Sensitivity: {sum(logistic_sensitivity_test) / len(logistic_sensitivity_test)}, Specificity: {sum(logistic_specificity_test) / len(logistic_specificity_test)}, AUC: {sum(logistic_auc_test) / len(logistic_auc_test)}\")\n",
    "print(f\"Random Forest - Accuracy: {sum(random_forest_accuracy_test) / len(random_forest_accuracy_test)}, Sensitivity: {sum(random_forest_sensitivity_test) / len(random_forest_sensitivity_test)}, Specificity: {sum(random_forest_specificity_test) / len(random_forest_specificity_test)}, AUC: {sum(random_forest_auc_test) / len(random_forest_auc_test)}\")\n",
    "print(f\"Bagging Classifier - Accuracy: {sum(bag_accuracy_test) / len(bag_accuracy_test)}, Sensitivity: {sum(bag_sensitivity_test) / len(bag_sensitivity_test)}, Specificity: {sum(bag_specificity_test) / len(bag_specificity_test)}, AUC: {sum(bag_auc_test) / len(bag_auc_test)}\")\n",
    "print(f\"OOB Score: {bag.oob_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df4e0a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.728724</td>\n",
       "      <td>0.873251</td>\n",
       "      <td>0.575368</td>\n",
       "      <td>0.724310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.784523</td>\n",
       "      <td>0.873415</td>\n",
       "      <td>0.690206</td>\n",
       "      <td>0.781811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>0.781944</td>\n",
       "      <td>0.869870</td>\n",
       "      <td>0.688650</td>\n",
       "      <td>0.779260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Sensitivity  Specificity       AUC\n",
       "0  Logistic Regression  0.728724     0.873251     0.575368  0.724310\n",
       "1        Random Forest  0.784523     0.873415     0.690206  0.781811\n",
       "2   Bagging Classifier  0.781944     0.869870     0.688650  0.779260"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metrics = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'Bagging Classifier'],\n",
    "    'Accuracy': [sum(logistic_accuracy_train) / len(logistic_accuracy_train), sum(random_forest_accuracy_train) / len(random_forest_accuracy_train), sum(bag_accuracy_train) / len(bag_accuracy_train)],\n",
    "    'Sensitivity': [sum(logistic_sensitivity_train) / len(logistic_sensitivity_train), sum(random_forest_sensitivity_train) / len(random_forest_sensitivity_train), sum(bag_sensitivity_train) / len(bag_sensitivity_train)],\n",
    "    'Specificity': [sum(logistic_specificity_train) / len(logistic_specificity_train), sum(random_forest_specificity_train) / len(random_forest_specificity_train), sum(bag_specificity_train) / len(bag_specificity_train)],\n",
    "    'AUC': [sum(logistic_auc_train) / len(logistic_auc_train), sum(random_forest_auc_train) / len(random_forest_auc_train), sum(bag_auc_train) / len(bag_auc_train)]\n",
    "})\n",
    "train_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03003441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.728510</td>\n",
       "      <td>0.872704</td>\n",
       "      <td>0.575917</td>\n",
       "      <td>0.724311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.761570</td>\n",
       "      <td>0.850566</td>\n",
       "      <td>0.667381</td>\n",
       "      <td>0.758973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>0.763609</td>\n",
       "      <td>0.851179</td>\n",
       "      <td>0.670931</td>\n",
       "      <td>0.761055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Sensitivity  Specificity       AUC\n",
       "0  Logistic Regression  0.728510     0.872704     0.575917  0.724311\n",
       "1        Random Forest  0.761570     0.850566     0.667381  0.758973\n",
       "2   Bagging Classifier  0.763609     0.851179     0.670931  0.761055"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'Bagging Classifier'],\n",
    "    'Accuracy': [sum(logistic_accuracy_test) / len(logistic_accuracy_test), sum(random_forest_accuracy_test) / len(random_forest_accuracy_test), sum(bag_accuracy_test) / len(bag_accuracy_test)],\n",
    "    'Sensitivity': [sum(logistic_sensitivity_test) / len(logistic_sensitivity_test), sum(random_forest_sensitivity_test) / len(random_forest_sensitivity_test), sum(bag_sensitivity_test) / len(bag_sensitivity_test)],\n",
    "    'Specificity': [sum(logistic_specificity_test) / len(logistic_specificity_test), sum(random_forest_specificity_test) / len(random_forest_specificity_test), sum(bag_specificity_test) / len(bag_specificity_test)],\n",
    "    'AUC': [sum(logistic_auc_test) / len(logistic_auc_test), sum(random_forest_auc_test) / len(random_forest_auc_test), sum(bag_auc_test) / len(bag_auc_test)]\n",
    "})\n",
    "test_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6fb126",
   "metadata": {},
   "source": [
    "**Feature Importances Per Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29a74eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/tmp/ipykernel_3269475/1821869398.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  random_forest_model.fit(X, y)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:804: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "protocol: 0.41955431130439064\n",
      "www_present: 0.2756030671231525\n",
      "sub_domain: 0.1784733809503829\n",
      "Logistic Regression:\n",
      "Index(['www_present', 'top_domain', 'url', 'domain', 'sub_domain', 'protocol'], dtype='object'): [0.0090159  0.13320302 0.32285809 0.41048689 0.51499088 6.70452586]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:791: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py:797: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "# figure out what the best features are for each model, then print out the top 3 features\n",
    "logistic_model.fit(X, y)\n",
    "random_forest_model.fit(X, y)\n",
    "bag.fit(X, y)\n",
    "\n",
    "rf_importances = random_forest_model.feature_importances_\n",
    "\n",
    "lr_importances = np.abs(logistic_model.coef_)\n",
    "feature_names = df.columns\n",
    "\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "for i in np.argsort(rf_importances)[::-1][:3]:\n",
    "    print(f\"{feature_names[i]}: {rf_importances[i]}\")\n",
    "\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "for i in np.argsort(lr_importances)[::-1][:3]:\n",
    "    print(f\"{feature_names[i]}: {lr_importances[0][i]}\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
